{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('log_reg_real_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',500)\n",
    "pd.set_option('display.max_columns',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15493 entries, 0 to 15492\n",
      "Data columns (total 24 columns):\n",
      "X                                      15493 non-null int64\n",
      "jumlah_kartu                           15493 non-null int64\n",
      "outstanding                            15493 non-null int64\n",
      "limit_kredit                           15493 non-null float64\n",
      "tagihan                                15493 non-null float64\n",
      "total_pemakaian_tunai                  15493 non-null float64\n",
      "total_pemakaian_retail                 15493 non-null float64\n",
      "sisa_tagihan_tidak_terbayar            15493 non-null float64\n",
      "kode_cabang                            15393 non-null object\n",
      "rasio_pembayaran                       15493 non-null float64\n",
      "persentasi_overlimit                   15493 non-null float64\n",
      "rasio_pembayaran_3bulan                15493 non-null float64\n",
      "rasio_pembayaran_6bulan                15493 non-null float64\n",
      "skor_delikuensi                        15493 non-null int64\n",
      "flag_kredit_macet                      15493 non-null int64\n",
      "jumlah_tahun_sejak_pembukaan_kredit    15493 non-null float64\n",
      "total_pemakaian                        15493 non-null float64\n",
      "sisa_tagihan_per_jumlah_kartu          15493 non-null float64\n",
      "sisa_tagihan_per_limit                 15493 non-null float64\n",
      "total_pemakaian_per_limit              15493 non-null float64\n",
      "pemakaian_3bln_per_limit               15493 non-null float64\n",
      "pemakaian_6bln_per_limit               15493 non-null float64\n",
      "utilisasi_3bulan                       15493 non-null float64\n",
      "utilisasi_6bulan                       15493 non-null float64\n",
      "dtypes: float64(18), int64(5), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>jumlah_kartu</th>\n",
       "      <th>outstanding</th>\n",
       "      <th>limit_kredit</th>\n",
       "      <th>tagihan</th>\n",
       "      <th>total_pemakaian_tunai</th>\n",
       "      <th>total_pemakaian_retail</th>\n",
       "      <th>sisa_tagihan_tidak_terbayar</th>\n",
       "      <th>kode_cabang</th>\n",
       "      <th>rasio_pembayaran</th>\n",
       "      <th>persentasi_overlimit</th>\n",
       "      <th>rasio_pembayaran_3bulan</th>\n",
       "      <th>rasio_pembayaran_6bulan</th>\n",
       "      <th>skor_delikuensi</th>\n",
       "      <th>flag_kredit_macet</th>\n",
       "      <th>jumlah_tahun_sejak_pembukaan_kredit</th>\n",
       "      <th>total_pemakaian</th>\n",
       "      <th>sisa_tagihan_per_jumlah_kartu</th>\n",
       "      <th>sisa_tagihan_per_limit</th>\n",
       "      <th>total_pemakaian_per_limit</th>\n",
       "      <th>pemakaian_3bln_per_limit</th>\n",
       "      <th>pemakaian_6bln_per_limit</th>\n",
       "      <th>utilisasi_3bulan</th>\n",
       "      <th>utilisasi_6bulan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36158</td>\n",
       "      <td>7000000.0</td>\n",
       "      <td>23437.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>26323.0</td>\n",
       "      <td>I</td>\n",
       "      <td>102.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.78</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.416667</td>\n",
       "      <td>94.0</td>\n",
       "      <td>13161.5</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.017810</td>\n",
       "      <td>0.013228</td>\n",
       "      <td>0.021949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>268691</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>254564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6769149</td>\n",
       "      <td>28000000.0</td>\n",
       "      <td>4159779.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040518</td>\n",
       "      <td>0.047703</td>\n",
       "      <td>0.249389</td>\n",
       "      <td>0.267853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3496732</td>\n",
       "      <td>21000000.0</td>\n",
       "      <td>111231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2536660.0</td>\n",
       "      <td>581334.0</td>\n",
       "      <td>G</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.01</td>\n",
       "      <td>22.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>2536660.0</td>\n",
       "      <td>145333.5</td>\n",
       "      <td>0.027683</td>\n",
       "      <td>0.120793</td>\n",
       "      <td>0.055971</td>\n",
       "      <td>0.016851</td>\n",
       "      <td>0.101912</td>\n",
       "      <td>0.346635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9402085</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>6099283.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2666558.0</td>\n",
       "      <td>5951865.0</td>\n",
       "      <td>A</td>\n",
       "      <td>95.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.49</td>\n",
       "      <td>99.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2666558.0</td>\n",
       "      <td>2975932.5</td>\n",
       "      <td>0.595186</td>\n",
       "      <td>0.266656</td>\n",
       "      <td>0.323027</td>\n",
       "      <td>0.131162</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.336571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X  jumlah_kartu  outstanding  limit_kredit    tagihan  \\\n",
       "0  1             2        36158     7000000.0    23437.0   \n",
       "1  2             2       268691    10000000.0   254564.0   \n",
       "2  3             3      6769149    28000000.0  4159779.0   \n",
       "3  4             4      3496732    21000000.0   111231.0   \n",
       "4  5             2      9402085    10000000.0  6099283.0   \n",
       "\n",
       "   total_pemakaian_tunai  total_pemakaian_retail  sisa_tagihan_tidak_terbayar  \\\n",
       "0                    0.0                    94.0                      26323.0   \n",
       "1                    0.0                  1012.0                          0.0   \n",
       "2                    0.0                     0.0                          0.0   \n",
       "3                    0.0               2536660.0                     581334.0   \n",
       "4                    0.0               2666558.0                    5951865.0   \n",
       "\n",
       "  kode_cabang  rasio_pembayaran  persentasi_overlimit  \\\n",
       "0           I            102.19                   0.0   \n",
       "1           A              0.00                   0.0   \n",
       "2           A            100.00                   0.0   \n",
       "3           G            100.00                   0.0   \n",
       "4           A             95.99                   0.0   \n",
       "\n",
       "   rasio_pembayaran_3bulan  rasio_pembayaran_6bulan  skor_delikuensi  \\\n",
       "0                    74.78                   100.00                0   \n",
       "1                     0.00                     0.00                0   \n",
       "2                   100.00                   100.91                0   \n",
       "3                    25.01                    22.64                0   \n",
       "4                    97.49                    99.84                0   \n",
       "\n",
       "   flag_kredit_macet  jumlah_tahun_sejak_pembukaan_kredit  total_pemakaian  \\\n",
       "0                  0                            15.416667             94.0   \n",
       "1                  0                             0.750000           1012.0   \n",
       "2                  0                            10.750000              0.0   \n",
       "3                  0                            19.750000        2536660.0   \n",
       "4                  0                             1.666667        2666558.0   \n",
       "\n",
       "   sisa_tagihan_per_jumlah_kartu  sisa_tagihan_per_limit  \\\n",
       "0                        13161.5                0.003760   \n",
       "1                            0.0                0.000000   \n",
       "2                            0.0                0.000000   \n",
       "3                       145333.5                0.027683   \n",
       "4                      2975932.5                0.595186   \n",
       "\n",
       "   total_pemakaian_per_limit  pemakaian_3bln_per_limit  \\\n",
       "0                   0.000013                  0.011719   \n",
       "1                   0.000101                  0.000000   \n",
       "2                   0.000000                  0.040518   \n",
       "3                   0.120793                  0.055971   \n",
       "4                   0.266656                  0.323027   \n",
       "\n",
       "   pemakaian_6bln_per_limit  utilisasi_3bulan  utilisasi_6bulan  \n",
       "0                  0.017810          0.013228          0.021949  \n",
       "1                  0.000000          0.004232          0.000300  \n",
       "2                  0.047703          0.249389          0.267853  \n",
       "3                  0.016851          0.101912          0.346635  \n",
       "4                  0.131162          0.707865          0.336571  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>jumlah_kartu</th>\n",
       "      <th>outstanding</th>\n",
       "      <th>limit_kredit</th>\n",
       "      <th>tagihan</th>\n",
       "      <th>total_pemakaian_tunai</th>\n",
       "      <th>total_pemakaian_retail</th>\n",
       "      <th>sisa_tagihan_tidak_terbayar</th>\n",
       "      <th>rasio_pembayaran</th>\n",
       "      <th>persentasi_overlimit</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_kredit_macet</th>\n",
       "      <th>jumlah_tahun_sejak_pembukaan_kredit</th>\n",
       "      <th>total_pemakaian</th>\n",
       "      <th>sisa_tagihan_per_jumlah_kartu</th>\n",
       "      <th>sisa_tagihan_per_limit</th>\n",
       "      <th>total_pemakaian_per_limit</th>\n",
       "      <th>pemakaian_3bln_per_limit</th>\n",
       "      <th>pemakaian_6bln_per_limit</th>\n",
       "      <th>utilisasi_3bulan</th>\n",
       "      <th>utilisasi_6bulan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15493.000000</td>\n",
       "      <td>15493.000000</td>\n",
       "      <td>1.549300e+04</td>\n",
       "      <td>1.549300e+04</td>\n",
       "      <td>1.549300e+04</td>\n",
       "      <td>1.549300e+04</td>\n",
       "      <td>1.549300e+04</td>\n",
       "      <td>1.549300e+04</td>\n",
       "      <td>15493.00000</td>\n",
       "      <td>15493.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15493.000000</td>\n",
       "      <td>15493.000000</td>\n",
       "      <td>1.549300e+04</td>\n",
       "      <td>1.549300e+04</td>\n",
       "      <td>15493.000000</td>\n",
       "      <td>15493.000000</td>\n",
       "      <td>15493.000000</td>\n",
       "      <td>15493.000000</td>\n",
       "      <td>15493.000000</td>\n",
       "      <td>15493.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7747.000000</td>\n",
       "      <td>2.506551</td>\n",
       "      <td>1.159833e+07</td>\n",
       "      <td>2.079833e+07</td>\n",
       "      <td>8.078663e+06</td>\n",
       "      <td>7.453291e+04</td>\n",
       "      <td>2.025857e+06</td>\n",
       "      <td>8.140875e+06</td>\n",
       "      <td>64.64712</td>\n",
       "      <td>3.343533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087717</td>\n",
       "      <td>6.634093</td>\n",
       "      <td>2.100421e+06</td>\n",
       "      <td>2.968060e+06</td>\n",
       "      <td>0.468246</td>\n",
       "      <td>0.109362</td>\n",
       "      <td>0.167446</td>\n",
       "      <td>0.202609</td>\n",
       "      <td>0.571102</td>\n",
       "      <td>0.533719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4472.588196</td>\n",
       "      <td>1.012655</td>\n",
       "      <td>2.408569e+07</td>\n",
       "      <td>2.955334e+07</td>\n",
       "      <td>1.761286e+07</td>\n",
       "      <td>6.184139e+05</td>\n",
       "      <td>7.927677e+06</td>\n",
       "      <td>1.922430e+07</td>\n",
       "      <td>794.16940</td>\n",
       "      <td>9.241921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282892</td>\n",
       "      <td>4.675454</td>\n",
       "      <td>8.092612e+06</td>\n",
       "      <td>6.262192e+06</td>\n",
       "      <td>0.473056</td>\n",
       "      <td>0.200159</td>\n",
       "      <td>0.192327</td>\n",
       "      <td>0.274293</td>\n",
       "      <td>0.411928</td>\n",
       "      <td>0.432350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+06</td>\n",
       "      <td>2.004300e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.566720e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-18138.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>-1.566720e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.632000</td>\n",
       "      <td>-0.126000</td>\n",
       "      <td>-0.569000</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3874.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000551e+06</td>\n",
       "      <td>5.000000e+06</td>\n",
       "      <td>8.182500e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7747.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.726943e+06</td>\n",
       "      <td>9.000000e+06</td>\n",
       "      <td>3.145857e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.010420e+05</td>\n",
       "      <td>2.750923e+06</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>2.480000e+05</td>\n",
       "      <td>1.209318e+06</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11620.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.064848e+07</td>\n",
       "      <td>2.200000e+07</td>\n",
       "      <td>7.404991e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.398000e+06</td>\n",
       "      <td>7.143198e+06</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>1.060000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.330000</td>\n",
       "      <td>1.512235e+06</td>\n",
       "      <td>3.088477e+06</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.917000</td>\n",
       "      <td>0.863000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15493.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>7.980586e+08</td>\n",
       "      <td>1.000000e+09</td>\n",
       "      <td>6.280000e+08</td>\n",
       "      <td>2.884057e+07</td>\n",
       "      <td>2.850000e+08</td>\n",
       "      <td>4.440000e+08</td>\n",
       "      <td>68983.00000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.416667</td>\n",
       "      <td>3.140000e+08</td>\n",
       "      <td>1.480000e+08</td>\n",
       "      <td>7.240000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>3.490000</td>\n",
       "      <td>8.110000</td>\n",
       "      <td>8.125671</td>\n",
       "      <td>9.730000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  X  jumlah_kartu   outstanding  limit_kredit       tagihan  \\\n",
       "count  15493.000000  15493.000000  1.549300e+04  1.549300e+04  1.549300e+04   \n",
       "mean    7747.000000      2.506551  1.159833e+07  2.079833e+07  8.078663e+06   \n",
       "std     4472.588196      1.012655  2.408569e+07  2.955334e+07  1.761286e+07   \n",
       "min        1.000000      1.000000  0.000000e+00  3.000000e+06  2.004300e+04   \n",
       "25%     3874.000000      2.000000  2.000551e+06  5.000000e+06  8.182500e+05   \n",
       "50%     7747.000000      2.000000  4.726943e+06  9.000000e+06  3.145857e+06   \n",
       "75%    11620.000000      3.000000  1.064848e+07  2.200000e+07  7.404991e+06   \n",
       "max    15493.000000     16.000000  7.980586e+08  1.000000e+09  6.280000e+08   \n",
       "\n",
       "       total_pemakaian_tunai  total_pemakaian_retail  \\\n",
       "count           1.549300e+04            1.549300e+04   \n",
       "mean            7.453291e+04            2.025857e+06   \n",
       "std             6.184139e+05            7.927677e+06   \n",
       "min             0.000000e+00           -1.566720e+07   \n",
       "25%             0.000000e+00            0.000000e+00   \n",
       "50%             0.000000e+00            2.010420e+05   \n",
       "75%             0.000000e+00            1.398000e+06   \n",
       "max             2.884057e+07            2.850000e+08   \n",
       "\n",
       "       sisa_tagihan_tidak_terbayar  rasio_pembayaran  persentasi_overlimit  \\\n",
       "count                 1.549300e+04       15493.00000          15493.000000   \n",
       "mean                  8.140875e+06          64.64712              3.343533   \n",
       "std                   1.922430e+07         794.16940              9.241921   \n",
       "min                   0.000000e+00      -18138.00000              0.000000   \n",
       "25%                   0.000000e+00           0.00000              0.000000   \n",
       "50%                   2.750923e+06          27.00000              0.000000   \n",
       "75%                   7.143198e+06         100.00000              1.060000   \n",
       "max                   4.440000e+08       68983.00000            190.000000   \n",
       "\n",
       "       ...  flag_kredit_macet  jumlah_tahun_sejak_pembukaan_kredit  \\\n",
       "count  ...       15493.000000                         15493.000000   \n",
       "mean   ...           0.087717                             6.634093   \n",
       "std    ...           0.282892                             4.675454   \n",
       "min    ...           0.000000                             0.750000   \n",
       "25%    ...           0.000000                             2.920000   \n",
       "50%    ...           0.000000                             5.666667   \n",
       "75%    ...           0.000000                             9.330000   \n",
       "max    ...           1.000000                            34.416667   \n",
       "\n",
       "       total_pemakaian  sisa_tagihan_per_jumlah_kartu  sisa_tagihan_per_limit  \\\n",
       "count     1.549300e+04                   1.549300e+04            15493.000000   \n",
       "mean      2.100421e+06                   2.968060e+06                0.468246   \n",
       "std       8.092612e+06                   6.262192e+06                0.473056   \n",
       "min      -1.566720e+07                   0.000000e+00                0.000000   \n",
       "25%       0.000000e+00                   0.000000e+00                0.000000   \n",
       "50%       2.480000e+05                   1.209318e+06                0.335000   \n",
       "75%       1.512235e+06                   3.088477e+06                0.930000   \n",
       "max       3.140000e+08                   1.480000e+08                7.240000   \n",
       "\n",
       "       total_pemakaian_per_limit  pemakaian_3bln_per_limit  \\\n",
       "count               15493.000000              15493.000000   \n",
       "mean                    0.109362                  0.167446   \n",
       "std                     0.200159                  0.192327   \n",
       "min                    -0.632000                 -0.126000   \n",
       "25%                     0.000000                  0.035200   \n",
       "50%                     0.022100                  0.108000   \n",
       "75%                     0.128000                  0.239000   \n",
       "max                     4.600000                  3.490000   \n",
       "\n",
       "       pemakaian_6bln_per_limit  utilisasi_3bulan  utilisasi_6bulan  \n",
       "count              15493.000000      15493.000000      15493.000000  \n",
       "mean                   0.202609          0.571102          0.533719  \n",
       "std                    0.274293          0.411928          0.432350  \n",
       "min                   -0.569000          0.000288          0.000000  \n",
       "25%                    0.032900          0.189000          0.155000  \n",
       "50%                    0.117000          0.575000          0.496000  \n",
       "75%                    0.285000          0.917000          0.863000  \n",
       "max                    8.110000          8.125671          9.730000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.912283\n",
       "1    0.087717\n",
       "Name: flag_kredit_macet, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.flag_kredit_macet.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    767\n",
       "F    144\n",
       "B    132\n",
       "I    102\n",
       "E     57\n",
       "H     33\n",
       "J     33\n",
       "G     30\n",
       "C     27\n",
       "K     17\n",
       "D     12\n",
       "Name: kode_cabang, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['flag_kredit_macet']==1]['kode_cabang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([946, 3454, 5089, 5533, 9206], dtype='int64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.kode_cabang.isnull()) & (df['flag_kredit_macet']==1)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(df[(df.kode_cabang.isnull()) & (df['flag_kredit_macet']==0)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['kode_cabang'].fillna('A',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Outlier data dengan Flag Kredit macet = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kolom=df.drop(['X','kode_cabang','flag_kredit_macet'],axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outlier_by_columns(df,col):\n",
    "    listindex=[]\n",
    "    for item in col:\n",
    "        q1=df[item].quantile(0.25)\n",
    "        q3=df[item].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower=q1-(iqr*1.5)\n",
    "        upper=q3+(iqr*1.5)\n",
    "        listindex.append(list(df[(df[item]<lower) | (df[item]>upper) & (df['flag_kredit_macet']==0)].index))\n",
    "    return listindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "listindexoutlier=detect_outlier_by_columns(df,kolom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{27: 5,\n",
       " 41: 1,\n",
       " 73: 8,\n",
       " 86: 3,\n",
       " 96: 6,\n",
       " 99: 1,\n",
       " 114: 3,\n",
       " 121: 4,\n",
       " 130: 2,\n",
       " 140: 5,\n",
       " 156: 9,\n",
       " 166: 6,\n",
       " 226: 7,\n",
       " 305: 5,\n",
       " 313: 10,\n",
       " 321: 3,\n",
       " 390: 1,\n",
       " 391: 4,\n",
       " 398: 2,\n",
       " 410: 9,\n",
       " 437: 2,\n",
       " 514: 2,\n",
       " 570: 2,\n",
       " 579: 7,\n",
       " 607: 8,\n",
       " 629: 5,\n",
       " 641: 2,\n",
       " 699: 4,\n",
       " 731: 5,\n",
       " 735: 7,\n",
       " 741: 2,\n",
       " 833: 1,\n",
       " 878: 5,\n",
       " 886: 7,\n",
       " 888: 1,\n",
       " 895: 4,\n",
       " 909: 2,\n",
       " 924: 5,\n",
       " 1011: 1,\n",
       " 1020: 1,\n",
       " 1051: 9,\n",
       " 1073: 6,\n",
       " 1102: 6,\n",
       " 1156: 7,\n",
       " 1181: 8,\n",
       " 1195: 1,\n",
       " 1204: 5,\n",
       " 1206: 2,\n",
       " 1218: 1,\n",
       " 1224: 4,\n",
       " 1318: 3,\n",
       " 1326: 6,\n",
       " 1330: 6,\n",
       " 1357: 2,\n",
       " 1378: 5,\n",
       " 1380: 1,\n",
       " 1389: 7,\n",
       " 1403: 1,\n",
       " 1417: 1,\n",
       " 1451: 2,\n",
       " 1476: 2,\n",
       " 1495: 3,\n",
       " 1519: 4,\n",
       " 1535: 4,\n",
       " 1559: 9,\n",
       " 1562: 4,\n",
       " 1605: 6,\n",
       " 1610: 2,\n",
       " 1638: 1,\n",
       " 1643: 9,\n",
       " 1679: 9,\n",
       " 1714: 3,\n",
       " 1724: 4,\n",
       " 1750: 9,\n",
       " 1757: 8,\n",
       " 1765: 5,\n",
       " 1771: 1,\n",
       " 1786: 3,\n",
       " 1798: 7,\n",
       " 1830: 8,\n",
       " 1853: 8,\n",
       " 1899: 4,\n",
       " 1912: 7,\n",
       " 1921: 2,\n",
       " 1937: 5,\n",
       " 1945: 4,\n",
       " 1965: 6,\n",
       " 1966: 8,\n",
       " 1974: 4,\n",
       " 1983: 6,\n",
       " 1996: 4,\n",
       " 2014: 2,\n",
       " 2028: 5,\n",
       " 2043: 7,\n",
       " 2059: 3,\n",
       " 2064: 2,\n",
       " 2069: 2,\n",
       " 2080: 8,\n",
       " 2100: 5,\n",
       " 2122: 2,\n",
       " 2154: 8,\n",
       " 2172: 6,\n",
       " 2233: 1,\n",
       " 2274: 5,\n",
       " 2277: 6,\n",
       " 2356: 2,\n",
       " 2384: 5,\n",
       " 2404: 1,\n",
       " 2410: 1,\n",
       " 2426: 7,\n",
       " 2427: 4,\n",
       " 2464: 3,\n",
       " 2469: 2,\n",
       " 2487: 5,\n",
       " 2500: 10,\n",
       " 2519: 2,\n",
       " 2523: 6,\n",
       " 2531: 9,\n",
       " 2534: 2,\n",
       " 2535: 8,\n",
       " 2540: 8,\n",
       " 2553: 2,\n",
       " 2564: 4,\n",
       " 2575: 8,\n",
       " 2615: 1,\n",
       " 2627: 2,\n",
       " 2673: 4,\n",
       " 2689: 4,\n",
       " 2810: 8,\n",
       " 2844: 3,\n",
       " 2864: 1,\n",
       " 2906: 10,\n",
       " 2935: 2,\n",
       " 2972: 4,\n",
       " 3011: 1,\n",
       " 3018: 2,\n",
       " 3019: 5,\n",
       " 3032: 2,\n",
       " 3034: 1,\n",
       " 3047: 3,\n",
       " 3073: 7,\n",
       " 3099: 7,\n",
       " 3100: 1,\n",
       " 3103: 7,\n",
       " 3149: 4,\n",
       " 3196: 6,\n",
       " 3227: 1,\n",
       " 3240: 2,\n",
       " 3285: 5,\n",
       " 3287: 6,\n",
       " 3297: 2,\n",
       " 3298: 2,\n",
       " 3329: 1,\n",
       " 3343: 4,\n",
       " 3351: 5,\n",
       " 3354: 4,\n",
       " 3448: 6,\n",
       " 3487: 4,\n",
       " 3515: 1,\n",
       " 3537: 6,\n",
       " 3538: 4,\n",
       " 3559: 4,\n",
       " 3612: 2,\n",
       " 3618: 1,\n",
       " 3628: 1,\n",
       " 3673: 1,\n",
       " 3674: 8,\n",
       " 3711: 9,\n",
       " 3727: 6,\n",
       " 3744: 1,\n",
       " 3750: 4,\n",
       " 3751: 8,\n",
       " 3758: 7,\n",
       " 3763: 5,\n",
       " 3776: 4,\n",
       " 3855: 7,\n",
       " 3856: 5,\n",
       " 3887: 1,\n",
       " 3899: 8,\n",
       " 3918: 3,\n",
       " 3950: 5,\n",
       " 3982: 5,\n",
       " 4016: 7,\n",
       " 4032: 2,\n",
       " 4035: 3,\n",
       " 4048: 2,\n",
       " 4063: 8,\n",
       " 4091: 2,\n",
       " 4095: 5,\n",
       " 4114: 2,\n",
       " 4146: 1,\n",
       " 4147: 2,\n",
       " 4185: 8,\n",
       " 4211: 1,\n",
       " 4218: 2,\n",
       " 4219: 1,\n",
       " 4231: 3,\n",
       " 4252: 4,\n",
       " 4274: 1,\n",
       " 4283: 3,\n",
       " 4303: 5,\n",
       " 4325: 9,\n",
       " 4334: 2,\n",
       " 4337: 8,\n",
       " 4439: 5,\n",
       " 4479: 4,\n",
       " 4495: 5,\n",
       " 4517: 2,\n",
       " 4538: 7,\n",
       " 4559: 6,\n",
       " 4620: 3,\n",
       " 4642: 2,\n",
       " 4670: 5,\n",
       " 4671: 5,\n",
       " 4688: 7,\n",
       " 4745: 6,\n",
       " 4783: 5,\n",
       " 4800: 1,\n",
       " 4818: 8,\n",
       " 4834: 5,\n",
       " 4896: 3,\n",
       " 4932: 2,\n",
       " 4963: 2,\n",
       " 4981: 5,\n",
       " 5019: 5,\n",
       " 5026: 2,\n",
       " 5028: 7,\n",
       " 5088: 5,\n",
       " 5091: 4,\n",
       " 5116: 6,\n",
       " 5184: 4,\n",
       " 5209: 2,\n",
       " 5293: 11,\n",
       " 5294: 2,\n",
       " 5329: 2,\n",
       " 5377: 3,\n",
       " 5397: 6,\n",
       " 5456: 3,\n",
       " 5469: 6,\n",
       " 5490: 9,\n",
       " 5559: 1,\n",
       " 5571: 5,\n",
       " 5647: 2,\n",
       " 5649: 11,\n",
       " 5720: 1,\n",
       " 5741: 4,\n",
       " 5773: 2,\n",
       " 5794: 9,\n",
       " 5859: 4,\n",
       " 5877: 8,\n",
       " 5941: 7,\n",
       " 5952: 7,\n",
       " 5991: 7,\n",
       " 5993: 4,\n",
       " 5995: 7,\n",
       " 6058: 9,\n",
       " 6075: 5,\n",
       " 6080: 5,\n",
       " 6140: 1,\n",
       " 6145: 7,\n",
       " 6148: 4,\n",
       " 6169: 5,\n",
       " 6239: 7,\n",
       " 6285: 3,\n",
       " 6290: 1,\n",
       " 6296: 6,\n",
       " 6310: 7,\n",
       " 6323: 1,\n",
       " 6325: 1,\n",
       " 6418: 4,\n",
       " 6450: 1,\n",
       " 6477: 8,\n",
       " 6490: 2,\n",
       " 6507: 1,\n",
       " 6516: 2,\n",
       " 6580: 1,\n",
       " 6587: 3,\n",
       " 6588: 2,\n",
       " 6645: 5,\n",
       " 6656: 4,\n",
       " 6661: 8,\n",
       " 6681: 10,\n",
       " 6711: 2,\n",
       " 6718: 2,\n",
       " 6794: 6,\n",
       " 6882: 9,\n",
       " 6903: 1,\n",
       " 6906: 1,\n",
       " 6912: 4,\n",
       " 6943: 1,\n",
       " 6947: 9,\n",
       " 6956: 2,\n",
       " 6976: 7,\n",
       " 7000: 8,\n",
       " 7040: 5,\n",
       " 7055: 7,\n",
       " 7106: 9,\n",
       " 7108: 8,\n",
       " 7112: 1,\n",
       " 7124: 10,\n",
       " 7130: 7,\n",
       " 7134: 5,\n",
       " 7154: 5,\n",
       " 7166: 7,\n",
       " 7169: 2,\n",
       " 7183: 8,\n",
       " 7206: 1,\n",
       " 7216: 4,\n",
       " 7225: 6,\n",
       " 7255: 8,\n",
       " 7279: 4,\n",
       " 7316: 8,\n",
       " 7317: 4,\n",
       " 7320: 2,\n",
       " 7323: 5,\n",
       " 7329: 8,\n",
       " 7383: 2,\n",
       " 7386: 2,\n",
       " 7399: 3,\n",
       " 7463: 1,\n",
       " 7493: 4,\n",
       " 7496: 6,\n",
       " 7522: 3,\n",
       " 7547: 4,\n",
       " 7549: 6,\n",
       " 7587: 6,\n",
       " 7589: 2,\n",
       " 7613: 2,\n",
       " 7625: 3,\n",
       " 7632: 1,\n",
       " 7651: 6,\n",
       " 7659: 2,\n",
       " 7769: 1,\n",
       " 7796: 2,\n",
       " 7821: 6,\n",
       " 7880: 6,\n",
       " 7902: 4,\n",
       " 7904: 6,\n",
       " 7929: 8,\n",
       " 7933: 7,\n",
       " 7943: 7,\n",
       " 7986: 5,\n",
       " 7995: 4,\n",
       " 8004: 2,\n",
       " 8015: 8,\n",
       " 8020: 2,\n",
       " 8056: 2,\n",
       " 8076: 3,\n",
       " 8077: 1,\n",
       " 8081: 2,\n",
       " 8098: 5,\n",
       " 8124: 8,\n",
       " 8132: 2,\n",
       " 8171: 9,\n",
       " 8172: 2,\n",
       " 8186: 8,\n",
       " 8207: 6,\n",
       " 8218: 4,\n",
       " 8230: 12,\n",
       " 8288: 2,\n",
       " 8289: 3,\n",
       " 8316: 5,\n",
       " 8454: 2,\n",
       " 8554: 8,\n",
       " 8557: 2,\n",
       " 8612: 3,\n",
       " 8767: 4,\n",
       " 8771: 9,\n",
       " 8773: 4,\n",
       " 8816: 6,\n",
       " 8855: 3,\n",
       " 8916: 2,\n",
       " 8924: 4,\n",
       " 8953: 1,\n",
       " 9008: 4,\n",
       " 9017: 7,\n",
       " 9068: 4,\n",
       " 9074: 5,\n",
       " 9076: 8,\n",
       " 9201: 4,\n",
       " 9216: 3,\n",
       " 9225: 6,\n",
       " 9228: 7,\n",
       " 9245: 4,\n",
       " 9274: 2,\n",
       " 9287: 8,\n",
       " 9309: 5,\n",
       " 9322: 6,\n",
       " 9371: 6,\n",
       " 9375: 2,\n",
       " 9405: 2,\n",
       " 9424: 5,\n",
       " 9429: 2,\n",
       " 9454: 5,\n",
       " 9480: 5,\n",
       " 9490: 8,\n",
       " 9539: 9,\n",
       " 9545: 6,\n",
       " 9582: 2,\n",
       " 9587: 6,\n",
       " 9673: 8,\n",
       " 9765: 1,\n",
       " 9769: 9,\n",
       " 9775: 7,\n",
       " 9812: 3,\n",
       " 9813: 6,\n",
       " 9819: 2,\n",
       " 9838: 4,\n",
       " 9854: 10,\n",
       " 9906: 2,\n",
       " 9929: 2,\n",
       " 9942: 3,\n",
       " 10015: 4,\n",
       " 10022: 6,\n",
       " 10025: 3,\n",
       " 10048: 9,\n",
       " 10052: 6,\n",
       " 10081: 3,\n",
       " 10088: 4,\n",
       " 10123: 1,\n",
       " 10146: 4,\n",
       " 10161: 9,\n",
       " 10163: 6,\n",
       " 10165: 4,\n",
       " 10190: 6,\n",
       " 10193: 2,\n",
       " 10200: 4,\n",
       " 10225: 3,\n",
       " 10248: 2,\n",
       " 10275: 3,\n",
       " 10281: 1,\n",
       " 10343: 7,\n",
       " 10361: 2,\n",
       " 10398: 3,\n",
       " 10410: 4,\n",
       " 10424: 2,\n",
       " 10426: 1,\n",
       " 10435: 1,\n",
       " 10569: 7,\n",
       " 10572: 7,\n",
       " 10623: 6,\n",
       " 10654: 8,\n",
       " 10656: 1,\n",
       " 10658: 1,\n",
       " 10688: 8,\n",
       " 10696: 1,\n",
       " 10700: 4,\n",
       " 10727: 9,\n",
       " 10760: 6,\n",
       " 10767: 1,\n",
       " 10771: 4,\n",
       " 10778: 4,\n",
       " 10799: 3,\n",
       " 10805: 3,\n",
       " 10811: 9,\n",
       " 10813: 4,\n",
       " 10818: 2,\n",
       " 10865: 3,\n",
       " 10870: 11,\n",
       " 10876: 7,\n",
       " 10877: 6,\n",
       " 10894: 8,\n",
       " 10910: 1,\n",
       " 10966: 6,\n",
       " 10978: 1,\n",
       " 10985: 6,\n",
       " 10995: 8,\n",
       " 11001: 6,\n",
       " 11030: 9,\n",
       " 11036: 1,\n",
       " 11037: 2,\n",
       " 11059: 2,\n",
       " 11068: 3,\n",
       " 11073: 7,\n",
       " 11111: 1,\n",
       " 11185: 1,\n",
       " 11189: 1,\n",
       " 11216: 2,\n",
       " 11219: 5,\n",
       " 11222: 8,\n",
       " 11242: 5,\n",
       " 11251: 7,\n",
       " 11277: 1,\n",
       " 11327: 7,\n",
       " 11352: 8,\n",
       " 11355: 1,\n",
       " 11379: 1,\n",
       " 11407: 4,\n",
       " 11421: 7,\n",
       " 11426: 1,\n",
       " 11490: 1,\n",
       " 11501: 2,\n",
       " 11518: 2,\n",
       " 11522: 4,\n",
       " 11550: 6,\n",
       " 11563: 2,\n",
       " 11568: 2,\n",
       " 11576: 7,\n",
       " 11592: 4,\n",
       " 11604: 10,\n",
       " 11622: 5,\n",
       " 11627: 2,\n",
       " 11631: 4,\n",
       " 11653: 1,\n",
       " 11668: 7,\n",
       " 11704: 10,\n",
       " 11742: 1,\n",
       " 11769: 5,\n",
       " 11774: 8,\n",
       " 11786: 4,\n",
       " 11793: 1,\n",
       " 11819: 7,\n",
       " 11839: 8,\n",
       " 11849: 6,\n",
       " 11865: 2,\n",
       " 11876: 2,\n",
       " 11888: 8,\n",
       " 11914: 2,\n",
       " 11946: 1,\n",
       " 11952: 6,\n",
       " 12019: 3,\n",
       " 12065: 1,\n",
       " 12091: 5,\n",
       " 12102: 7,\n",
       " 12136: 2,\n",
       " 12149: 6,\n",
       " 12169: 7,\n",
       " 12190: 4,\n",
       " 12197: 6,\n",
       " 12207: 9,\n",
       " 12259: 3,\n",
       " 12281: 5,\n",
       " 12299: 7,\n",
       " 12300: 6,\n",
       " 12303: 11,\n",
       " 12315: 1,\n",
       " 12337: 1,\n",
       " 12344: 2,\n",
       " 12362: 4,\n",
       " 12383: 6,\n",
       " 12384: 5,\n",
       " 12402: 2,\n",
       " 12416: 5,\n",
       " 12441: 3,\n",
       " 12449: 2,\n",
       " 12460: 2,\n",
       " 12599: 6,\n",
       " 12629: 1,\n",
       " 12638: 5,\n",
       " 12639: 1,\n",
       " 12645: 2,\n",
       " 12670: 6,\n",
       " 12698: 2,\n",
       " 12739: 2,\n",
       " 12759: 7,\n",
       " 12779: 7,\n",
       " 12800: 3,\n",
       " 12824: 6,\n",
       " 12831: 6,\n",
       " 12860: 5,\n",
       " 12876: 1,\n",
       " 12885: 2,\n",
       " 12889: 5,\n",
       " 12899: 2,\n",
       " 12932: 6,\n",
       " 12952: 2,\n",
       " 12992: 6,\n",
       " 13005: 3,\n",
       " 13023: 6,\n",
       " 13056: 8,\n",
       " 13070: 4,\n",
       " 13071: 2,\n",
       " 13123: 5,\n",
       " 13127: 9,\n",
       " 13161: 9,\n",
       " 13177: 7,\n",
       " 13186: 7,\n",
       " 13187: 4,\n",
       " 13191: 1,\n",
       " 13218: 7,\n",
       " 13232: 1,\n",
       " 13252: 2,\n",
       " 13303: 4,\n",
       " 13310: 5,\n",
       " 13335: 3,\n",
       " 13339: 6,\n",
       " 13367: 8,\n",
       " 13389: 5,\n",
       " 13394: 8,\n",
       " 13398: 8,\n",
       " 13401: 1,\n",
       " 13441: 8,\n",
       " 13569: 3,\n",
       " 13580: 8,\n",
       " 13591: 5,\n",
       " 13646: 2,\n",
       " 13685: 2,\n",
       " 13696: 2,\n",
       " 13699: 7,\n",
       " 13713: 2,\n",
       " 13717: 2,\n",
       " 13741: 4,\n",
       " 13770: 2,\n",
       " 13784: 1,\n",
       " 13813: 2,\n",
       " 13826: 3,\n",
       " 13832: 3,\n",
       " 13841: 9,\n",
       " 13941: 1,\n",
       " 13961: 3,\n",
       " 14029: 2,\n",
       " 14045: 1,\n",
       " 14052: 7,\n",
       " 14060: 9,\n",
       " 14078: 7,\n",
       " 14147: 2,\n",
       " 14213: 6,\n",
       " 14252: 2,\n",
       " 14269: 7,\n",
       " 14300: 2,\n",
       " 14307: 3,\n",
       " 14340: 2,\n",
       " 14400: 4,\n",
       " 14431: 2,\n",
       " 14514: 8,\n",
       " 14516: 3,\n",
       " 14521: 4,\n",
       " 14593: 7,\n",
       " 14622: 4,\n",
       " 14658: 9,\n",
       " 14663: 1,\n",
       " 14725: 1,\n",
       " 14726: 2,\n",
       " 14744: 2,\n",
       " 14777: 4,\n",
       " 14785: 2,\n",
       " 14810: 8,\n",
       " 14850: 1,\n",
       " 14873: 1,\n",
       " 14881: 1,\n",
       " 14944: 1,\n",
       " 14956: 10,\n",
       " 14958: 2,\n",
       " 14969: 7,\n",
       " 14971: 8,\n",
       " 14974: 8,\n",
       " 15004: 2,\n",
       " 15032: 1,\n",
       " 15054: 10,\n",
       " 15127: 6,\n",
       " 15128: 5,\n",
       " 15139: 8,\n",
       " 15188: 6,\n",
       " 15219: 2,\n",
       " 15229: 8,\n",
       " 15236: 9,\n",
       " 15262: 3,\n",
       " 15263: 7,\n",
       " 15325: 5,\n",
       " 15335: 7,\n",
       " 15356: 2,\n",
       " 15413: 2,\n",
       " 15447: 6,\n",
       " 10: 5,\n",
       " 16: 2,\n",
       " 46: 6,\n",
       " 54: 3,\n",
       " 82: 3,\n",
       " 92: 7,\n",
       " 101: 8,\n",
       " 103: 4,\n",
       " 136: 4,\n",
       " 152: 5,\n",
       " 157: 6,\n",
       " 160: 7,\n",
       " 172: 8,\n",
       " 174: 5,\n",
       " 176: 6,\n",
       " 202: 6,\n",
       " 230: 6,\n",
       " 233: 5,\n",
       " 240: 8,\n",
       " 259: 2,\n",
       " 264: 7,\n",
       " 267: 4,\n",
       " 269: 3,\n",
       " 286: 8,\n",
       " 308: 5,\n",
       " 339: 4,\n",
       " 352: 7,\n",
       " 359: 5,\n",
       " 373: 6,\n",
       " 374: 6,\n",
       " 400: 8,\n",
       " 414: 3,\n",
       " 435: 5,\n",
       " 442: 5,\n",
       " 446: 4,\n",
       " 450: 5,\n",
       " 471: 6,\n",
       " 489: 6,\n",
       " 496: 5,\n",
       " 500: 4,\n",
       " 521: 7,\n",
       " 522: 6,\n",
       " 528: 5,\n",
       " 534: 2,\n",
       " 551: 6,\n",
       " 560: 6,\n",
       " 562: 4,\n",
       " 578: 5,\n",
       " 600: 5,\n",
       " 614: 6,\n",
       " 659: 4,\n",
       " 661: 7,\n",
       " 674: 4,\n",
       " 736: 3,\n",
       " 748: 7,\n",
       " 759: 1,\n",
       " 761: 4,\n",
       " 776: 7,\n",
       " 777: 7,\n",
       " 778: 5,\n",
       " 779: 5,\n",
       " 796: 5,\n",
       " 805: 5,\n",
       " 808: 8,\n",
       " 813: 5,\n",
       " 814: 5,\n",
       " 824: 4,\n",
       " 825: 6,\n",
       " 839: 4,\n",
       " 855: 1,\n",
       " 870: 4,\n",
       " 874: 6,\n",
       " 876: 7,\n",
       " 877: 3,\n",
       " 889: 7,\n",
       " 900: 4,\n",
       " 926: 4,\n",
       " 937: 6,\n",
       " 940: 8,\n",
       " 942: 8,\n",
       " 988: 5,\n",
       " 990: 5,\n",
       " 993: 4,\n",
       " 994: 5,\n",
       " 1001: 4,\n",
       " 1025: 4,\n",
       " 1054: 5,\n",
       " 1068: 5,\n",
       " 1104: 6,\n",
       " 1122: 6,\n",
       " 1143: 5,\n",
       " 1163: 4,\n",
       " 1175: 7,\n",
       " 1187: 7,\n",
       " 1192: 8,\n",
       " 1198: 8,\n",
       " 1200: 3,\n",
       " 1225: 7,\n",
       " 1262: 4,\n",
       " 1270: 5,\n",
       " 1329: 4,\n",
       " 1339: 6,\n",
       " 1345: 8,\n",
       " 1361: 9,\n",
       " 1362: 6,\n",
       " 1371: 5,\n",
       " 1375: 4,\n",
       " 1384: 3,\n",
       " 1441: 10,\n",
       " 1444: 7,\n",
       " 1459: 5,\n",
       " 1466: 8,\n",
       " 1472: 4,\n",
       " 1490: 6,\n",
       " 1503: 9,\n",
       " 1516: 5,\n",
       " 1521: 5,\n",
       " 1524: 6,\n",
       " 1530: 7,\n",
       " 1531: 3,\n",
       " 1532: 5,\n",
       " 1534: 5,\n",
       " 1539: 6,\n",
       " 1553: 5,\n",
       " 1565: 6,\n",
       " 1588: 2,\n",
       " 1591: 5,\n",
       " 1614: 7,\n",
       " 1621: 8,\n",
       " 1631: 7,\n",
       " 1642: 7,\n",
       " 1650: 5,\n",
       " 1653: 7,\n",
       " 1665: 10,\n",
       " 1669: 8,\n",
       " 1708: 3,\n",
       " 1709: 3,\n",
       " 1712: 6,\n",
       " 1723: 3,\n",
       " 1754: 4,\n",
       " 1762: 3,\n",
       " 1799: 6,\n",
       " 1802: 4,\n",
       " 1804: 5,\n",
       " 1808: 8,\n",
       " 1843: 5,\n",
       " 1856: 3,\n",
       " 1904: 2,\n",
       " 1913: 7,\n",
       " 1927: 4,\n",
       " 1950: 5,\n",
       " 1961: 5,\n",
       " 1964: 8,\n",
       " 1970: 4,\n",
       " 1991: 7,\n",
       " 2020: 1,\n",
       " 2034: 6,\n",
       " 2066: 5,\n",
       " 2072: 7,\n",
       " 2088: 7,\n",
       " 2095: 4,\n",
       " 2097: 5,\n",
       " 2107: 9,\n",
       " 2149: 7,\n",
       " 2157: 4,\n",
       " 2180: 2,\n",
       " 2188: 3,\n",
       " 2190: 7,\n",
       " 2212: 5,\n",
       " 2217: 2,\n",
       " 2222: 7,\n",
       " 2225: 6,\n",
       " 2250: 7,\n",
       " 2255: 3,\n",
       " 2258: 5,\n",
       " 2262: 6,\n",
       " 2268: 7,\n",
       " 2275: 7,\n",
       " 2305: 6,\n",
       " 2344: 6,\n",
       " 2365: 5,\n",
       " 2370: 5,\n",
       " 2381: 5,\n",
       " 2386: 4,\n",
       " 2389: 5,\n",
       " 2429: 8,\n",
       " 2454: 6,\n",
       " 2472: 6,\n",
       " 2538: 8,\n",
       " 2551: 6,\n",
       " 2559: 8,\n",
       " 2570: 7,\n",
       " 2578: 3,\n",
       " 2601: 7,\n",
       " 2618: 6,\n",
       " 2622: 4,\n",
       " 2641: 6,\n",
       " 2664: 7,\n",
       " 2680: 3,\n",
       " 2682: 7,\n",
       " 2686: 5,\n",
       " 2699: 6,\n",
       " 2709: 5,\n",
       " 2710: 6,\n",
       " 2752: 7,\n",
       " 2759: 5,\n",
       " 2772: 5,\n",
       " 2786: 7,\n",
       " 2794: 6,\n",
       " 2812: 11,\n",
       " 2816: 4,\n",
       " 2820: 2,\n",
       " 2822: 6,\n",
       " 2834: 5,\n",
       " 2852: 4,\n",
       " 2871: 5,\n",
       " 2878: 5,\n",
       " 2910: 2,\n",
       " 2920: 5,\n",
       " 2944: 3,\n",
       " 2950: 2,\n",
       " 2963: 5,\n",
       " 2964: 5,\n",
       " 2993: 4,\n",
       " 3003: 6,\n",
       " 3009: 4,\n",
       " 3016: 6,\n",
       " 3027: 5,\n",
       " 3048: 5,\n",
       " 3056: 3,\n",
       " 3072: 4,\n",
       " 3124: 2,\n",
       " 3126: 5,\n",
       " 3170: 4,\n",
       " 3171: 5,\n",
       " 3193: 4,\n",
       " 3195: 5,\n",
       " 3255: 4,\n",
       " 3265: 6,\n",
       " 3274: 5,\n",
       " 3277: 5,\n",
       " 3281: 8,\n",
       " 3305: 5,\n",
       " 3327: 4,\n",
       " 3331: 3,\n",
       " 3334: 4,\n",
       " 3344: 8,\n",
       " 3347: 7,\n",
       " 3353: 5,\n",
       " 3355: 5,\n",
       " 3372: 4,\n",
       " 3385: 3,\n",
       " 3395: 7,\n",
       " 3417: 3,\n",
       " 3422: 5,\n",
       " 3425: 5,\n",
       " 3436: 1,\n",
       " 3440: 3,\n",
       " 3444: 7,\n",
       " 3445: 6,\n",
       " 3458: 4,\n",
       " 3463: 6,\n",
       " 3471: 1,\n",
       " 3484: 3,\n",
       " 3511: 5,\n",
       " 3528: 3,\n",
       " 3530: 4,\n",
       " 3567: 10,\n",
       " 3582: 7,\n",
       " 3592: 5,\n",
       " 3602: 5,\n",
       " 3646: 4,\n",
       " 3647: 7,\n",
       " 3651: 2,\n",
       " 3676: 11,\n",
       " 3694: 5,\n",
       " 3709: 5,\n",
       " 3712: 6,\n",
       " 3716: 7,\n",
       " 3722: 7,\n",
       " 3738: 5,\n",
       " 3787: 2,\n",
       " 3795: 8,\n",
       " 3809: 5,\n",
       " 3818: 3,\n",
       " 3917: 6,\n",
       " 3934: 5,\n",
       " 3963: 5,\n",
       " 3966: 1,\n",
       " 3980: 5,\n",
       " 3981: 3,\n",
       " 4009: 2,\n",
       " 4030: 5,\n",
       " 4031: 8,\n",
       " 4041: 8,\n",
       " 4058: 5,\n",
       " 4060: 6,\n",
       " 4075: 5,\n",
       " 4088: 6,\n",
       " 4093: 7,\n",
       " 4132: 4,\n",
       " 4142: 5,\n",
       " 4163: 4,\n",
       " 4178: 4,\n",
       " 4191: 6,\n",
       " 4237: 4,\n",
       " 4279: 5,\n",
       " 4289: 5,\n",
       " 4326: 4,\n",
       " 4344: 7,\n",
       " 4345: 7,\n",
       " 4349: 5,\n",
       " 4354: 5,\n",
       " 4359: 8,\n",
       " 4364: 1,\n",
       " 4379: 7,\n",
       " 4411: 3,\n",
       " 4422: 3,\n",
       " 4435: 5,\n",
       " 4444: 6,\n",
       " 4457: 4,\n",
       " 4490: 5,\n",
       " 4492: 2,\n",
       " 4500: 5,\n",
       " 4510: 5,\n",
       " 4522: 5,\n",
       " 4525: 2,\n",
       " 4547: 3,\n",
       " 4552: 7,\n",
       " 4557: 8,\n",
       " 4613: 5,\n",
       " 4623: 4,\n",
       " 4635: 3,\n",
       " 4639: 11,\n",
       " 4646: 8,\n",
       " 4647: 6,\n",
       " 4649: 7,\n",
       " ...}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_outlier={}\n",
    "for item in listindexoutlier:\n",
    "    for idx in item:\n",
    "        if idx in dict_outlier:\n",
    "            dict_outlier[idx]+=1\n",
    "        else:\n",
    "            dict_outlier[idx]=1\n",
    "dict_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3019"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxtodrop=[]\n",
    "for key,value in dict_outlier.items():\n",
    "    if value >=3 :\n",
    "        idxtodrop.append(key)\n",
    "len(idxtodrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(idxtodrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12379 entries, 0 to 15492\n",
      "Data columns (total 24 columns):\n",
      "X                                      12379 non-null int64\n",
      "jumlah_kartu                           12379 non-null int64\n",
      "outstanding                            12379 non-null int64\n",
      "limit_kredit                           12379 non-null float64\n",
      "tagihan                                12379 non-null float64\n",
      "total_pemakaian_tunai                  12379 non-null float64\n",
      "total_pemakaian_retail                 12379 non-null float64\n",
      "sisa_tagihan_tidak_terbayar            12379 non-null float64\n",
      "kode_cabang                            12379 non-null category\n",
      "rasio_pembayaran                       12379 non-null float64\n",
      "persentasi_overlimit                   12379 non-null float64\n",
      "rasio_pembayaran_3bulan                12379 non-null float64\n",
      "rasio_pembayaran_6bulan                12379 non-null float64\n",
      "skor_delikuensi                        12379 non-null int64\n",
      "flag_kredit_macet                      12379 non-null int64\n",
      "jumlah_tahun_sejak_pembukaan_kredit    12379 non-null float64\n",
      "total_pemakaian                        12379 non-null float64\n",
      "sisa_tagihan_per_jumlah_kartu          12379 non-null float64\n",
      "sisa_tagihan_per_limit                 12379 non-null float64\n",
      "total_pemakaian_per_limit              12379 non-null float64\n",
      "pemakaian_3bln_per_limit               12379 non-null float64\n",
      "pemakaian_6bln_per_limit               12379 non-null float64\n",
      "utilisasi_3bulan                       12379 non-null float64\n",
      "utilisasi_6bulan                       12379 non-null float64\n",
      "dtypes: category(1), float64(18), int64(5)\n",
      "memory usage: 2.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.890379\n",
       "1    0.109621\n",
       "Name: flag_kredit_macet, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.flag_kredit_macet.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 0, 6, 1, 4, ..., 5, 2, 9, 7, 3]\n",
       "Length: 11\n",
       "Categories (11, int64): [8, 0, 6, 1, ..., 2, 9, 7, 3]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['kode_cabang'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['kode_cabang']=df['kode_cabang'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['kode_cabang'].cat.categories=list(range(0,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['X','flag_kredit_macet'],axis=1)\n",
    "y = df['flag_kredit_macet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)\n",
    "prediction_test = logmodel.predict(X_test)\n",
    "prediction_train = logmodel.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93      3292\n",
      "           1       0.40      0.18      0.25       422\n",
      "\n",
      "    accuracy                           0.88      3714\n",
      "   macro avg       0.65      0.57      0.59      3714\n",
      "weighted avg       0.84      0.88      0.85      3714\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93      7730\n",
      "           1       0.36      0.18      0.24       935\n",
      "\n",
      "    accuracy                           0.88      8665\n",
      "   macro avg       0.63      0.57      0.58      8665\n",
      "weighted avg       0.85      0.88      0.86      8665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('class report data test')\n",
    "print(classification_report(y_test,prediction_test))\n",
    "print('============================================')\n",
    "print('class report data train')\n",
    "print(classification_report(y_train,prediction_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_data=df[df['flag_kredit_macet']==1]\n",
    "mayority_data=df[df['flag_kredit_macet']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_for_mayority=np.random.choice(mayority_data.index,len(minority_data))\n",
    "df_class_0=df.loc[index_for_mayority]\n",
    "undersampling_df=pd.concat([df_class_0,minority_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1357\n",
       "0    1357\n",
       "Name: flag_kredit_macet, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampling_df['flag_kredit_macet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_u = undersampling_df.drop(['X','flag_kredit_macet'],axis=1)\n",
    "y_u = undersampling_df['flag_kredit_macet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(x_u,y_u,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = logmodel.predict(X_test)\n",
    "prediction_train = logmodel.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.47      0.51       397\n",
      "           1       0.56      0.65      0.60       418\n",
      "\n",
      "    accuracy                           0.56       815\n",
      "   macro avg       0.56      0.56      0.55       815\n",
      "weighted avg       0.56      0.56      0.56       815\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.52      0.57       960\n",
      "           1       0.58      0.68      0.63       939\n",
      "\n",
      "    accuracy                           0.60      1899\n",
      "   macro avg       0.60      0.60      0.60      1899\n",
      "weighted avg       0.60      0.60      0.60      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('class report data test')\n",
    "print(classification_report(y_test,prediction_test))\n",
    "print('============================================')\n",
    "print('class report data train')\n",
    "print(classification_report(y_train,prediction_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros=RandomOverSampler()\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ros,y_ros=ros.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_over_all=pd.DataFrame(X_ros,columns=x.columns)\n",
    "df_over_all['flag_kredit_macet'] = y_ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7697\n",
       "0    7697\n",
       "Name: flag_kredit_macet, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_over_all['flag_kredit_macet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_o = df_over_all.drop(['flag_kredit_macet'],axis=1)\n",
    "y_o = df_over_all['flag_kredit_macet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(x_o,y_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = logmodel.predict(X_test)\n",
    "prediction_train = logmodel.predict(x_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.42      0.58      3325\n",
      "           1       0.12      0.69      0.21       389\n",
      "\n",
      "    accuracy                           0.45      3714\n",
      "   macro avg       0.52      0.56      0.39      3714\n",
      "weighted avg       0.84      0.45      0.54      3714\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.42      0.49      7697\n",
      "           1       0.55      0.71      0.62      7697\n",
      "\n",
      "    accuracy                           0.57     15394\n",
      "   macro avg       0.57      0.57      0.56     15394\n",
      "weighted avg       0.57      0.57      0.56     15394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('class report data test')\n",
    "print(classification_report(y_test,prediction_test))\n",
    "print('============================================')\n",
    "print('class report data train')\n",
    "print(classification_report(y_o,prediction_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_report_by_algo_smote(x,y):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(x,y)\n",
    "    sm=SMOTE(random_state=101)\n",
    "    X_sm,y_sm=sm.fit_sample(X_train,y_train)\n",
    "    clf=LogisticRegression()\n",
    "    clf.fit(X_sm,y_sm)\n",
    "    \n",
    "    prediction_test = clf.predict(X_test)\n",
    "    prediction_train = clf.predict(X_sm)\n",
    "    \n",
    "    print('class report data test')\n",
    "    print(classification_report(y_test,prediction_test))\n",
    "    print('============================================')\n",
    "    print('class report data train')\n",
    "    print(classification_report(y_sm,prediction_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.55      0.69      2761\n",
      "           1       0.15      0.67      0.25       334\n",
      "\n",
      "    accuracy                           0.56      3095\n",
      "   macro avg       0.54      0.61      0.47      3095\n",
      "weighted avg       0.85      0.56      0.64      3095\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.55      0.59      8261\n",
      "           1       0.60      0.68      0.64      8261\n",
      "\n",
      "    accuracy                           0.62     16522\n",
      "   macro avg       0.62      0.62      0.61     16522\n",
      "weighted avg       0.62      0.62      0.61     16522\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "class_report_by_algo_smote(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari hasil LogisticRegression menggunakan Smote, underSampling, dan OverSampling makan didapat hasil OverSampling yang terbaik. maka kita akan melakukan Cut Off pada Model OverSampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUT OFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(x_o,y_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = logmodel.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "precition_cut_off = []\n",
    "\n",
    "for item in proba[:,1]:\n",
    "    if item > 0.45:\n",
    "        precition_cut_off.append(1)\n",
    "    else :\n",
    "        precition_cut_off.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.42      0.58      3325\n",
      "           1       0.12      0.69      0.21       389\n",
      "\n",
      "    accuracy                           0.45      3714\n",
      "   macro avg       0.52      0.56      0.39      3714\n",
      "weighted avg       0.84      0.45      0.54      3714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,precition_cut_off))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39496435, 0.60503565],\n",
       "       [0.48829314, 0.51170686],\n",
       "       [0.50488025, 0.49511975],\n",
       "       ...,\n",
       "       [0.51302267, 0.48697733],\n",
       "       [0.40408632, 0.59591368],\n",
       "       [0.54125899, 0.45874101]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Weight balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight={0: 1, 1: 12}, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=30, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=101, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression(class_weight={0:1,1:12},max_iter=30,random_state=101)\n",
    "logmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = logmodel.predict(X_test)\n",
    "prediction_train = logmodel.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.25      0.40      3325\n",
      "           1       0.11      0.78      0.19       389\n",
      "\n",
      "    accuracy                           0.31      3714\n",
      "   macro avg       0.51      0.52      0.29      3714\n",
      "weighted avg       0.82      0.31      0.38      3714\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.25      0.39      7697\n",
      "           1       0.12      0.79      0.20       968\n",
      "\n",
      "    accuracy                           0.31      8665\n",
      "   macro avg       0.51      0.52      0.30      8665\n",
      "weighted avg       0.82      0.31      0.37      8665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('class report data test')\n",
    "print(classification_report(y_test,prediction_test))\n",
    "print('============================================')\n",
    "print('class report data train')\n",
    "print(classification_report(y_train,prediction_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Weight  Logistic Regression with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters : {'class_weight': {0: 0.19210526315789472, 1: 0.8078947368421052}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22909ea9470>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "weights = np.linspace(0.05, 0.95, 20)\n",
    "\n",
    "gsc = GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid={\n",
    "        'class_weight': [{0: x, 1: 1.0-x} for x in weights]\n",
    "    },\n",
    "    scoring='f1',\n",
    "    cv=3\n",
    ")\n",
    "grid_result = gsc.fit(x, y)\n",
    "\n",
    "print(\"Best parameters : %s\" % grid_result.best_params_)\n",
    "\n",
    "# Plot the weights vs f1 score\n",
    "dataz = pd.DataFrame({ 'score': grid_result.cv_results_['mean_test_score'],\n",
    "                       'weight': weights })\n",
    "dataz.plot(x='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0,\n",
       "                   class_weight={0: 0.19210526315789472, 1: 0.8078947368421052},\n",
       "                   dual=False, fit_intercept=True, intercept_scaling=1,\n",
       "                   l1_ratio=None, max_iter=100, multi_class='warn', n_jobs=None,\n",
       "                   penalty='l2', random_state=None, solver='warn', tol=0.0001,\n",
       "                   verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression(class_weight={0: 0.19210526315789472, 1: 0.8078947368421052})\n",
    "logmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = logmodel.predict(X_test)\n",
    "prediction_train = logmodel.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class report data test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.75      0.83      3292\n",
      "           1       0.21      0.52      0.30       422\n",
      "\n",
      "    accuracy                           0.72      3714\n",
      "   macro avg       0.57      0.63      0.56      3714\n",
      "weighted avg       0.84      0.72      0.77      3714\n",
      "\n",
      "============================================\n",
      "class report data train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.74      0.83      7730\n",
      "           1       0.20      0.55      0.30       935\n",
      "\n",
      "    accuracy                           0.72      8665\n",
      "   macro avg       0.57      0.64      0.56      8665\n",
      "weighted avg       0.85      0.72      0.77      8665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('class report data test')\n",
    "print(classification_report(y_test,prediction_test))\n",
    "print('============================================')\n",
    "print('class report data train')\n",
    "print(classification_report(y_train,prediction_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
